# -*- coding: utf-8 -*-
"""Q2_Recommendation_System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cBs6AyyWHM3sOCdyjnfngHYxO2VlVY8k
"""

# -*- coding: utf-8 -*-
"""
CS 351 - Artificial Intelligence 
Assignment 3, Question 2

Student 1(Syed Musatafa and 06554):


"""

import numpy as np
import matplotlib.pyplot as plt

def computeError(R,predR):
    
    """Your code to calculate MSE goes here"""    
    user, items= np.shape(R)
    MSE = 0
    total =0
    for i in range(user):
        for j in range(items):
            square_Err = (R[i][j]-predR[i][j])**2
            if R[i,j]!= 0:
                MSE = MSE + square_Err
                total+=1
            # if i == 0 and j ==0:
            #     print(f"The MSE matrix = {MSE}")
    MSE = MSE/total
    return MSE

"""
This fucntion takes P (m x k) and Q(k x n) matrices alongwith user bias (U) and item bias (I) and returns predicted rating. 
where m = No of Users, n = No of items
p = {user_feature matrix}
Q = {Item feature matrix}
"""
def getPredictedRatings(P,Q,U,I):

    """Your code to predict ratinngs goes here"""   
    '''IN this question we only need to multiply P * Q
        But first add U and I  
    ''' 
    P = P + np.transpose(U)
    Q = np.transpose(np.transpose(Q)+ np.transpose(I))
    # print(np.shape(Q))
    

    pred = np.dot(P, Q)
    # print(np.shape(pred))
    
    return pred

"""This fucntion runs gradient descent to minimze error in ratings by adjusting P, Q, U and I matrices based on gradients.
   The functions returns a list of (iter,mse) tuple that lists mse in each iteration
"""
def runGradientDescent(R,P,Q,U,I,iterations,alpha):
    
    # print(np.shape(P))
    # print(np.shape(Q))
    
    users, _= np.shape(P)
    I_row , items = np.shape(Q)  
    stats = []

    
    """Your gradient descent code goes here"""    
    for epoch in range(iterations):
        predicted = getPredictedRatings(P,Q,U,I)
        error = R - predicted
        
        for i in range(users):
            for j in range(items):
                if not R[i, j] == 0: 
                    U[0,i]=U[0,i]+2*alpha*error[i,j]
                    I[0,j]=I[0,j]+2*alpha*error[i,j]
                    P[i,:]=P[i,:]+2*alpha*error[i,j]*Q[:,j] #  P[i,:] is all the features for a user 
                    Q[:,j]=Q[:,j]+2*alpha*error[i,j]*P[i,:]

        stats.append((epoch,computeError(R, predicted)))
    """"finally returns (iter,mse) values in a list"""
    # print(predicted)
    return stats

""" 
This method applies matrix factorization to predict unobserved values in a rating matrix (R) using gradient descent.
K is number of latent variables and alpha is the learning rate to be used in gradient decent
"""    

def matrixFactorization(R,k,iterations, alpha):

    """Your code to initialize P, Q, U and I matrices goes here. P and Q will be randomly initialized whereas U and I will be initialized as zeros. 
    Be careful about the dimension of these matrices
    """

    users, items = np.shape(R)
    P = np.random.normal(scale=1/k, size=(users, k))
    Q = np.random.normal(scale=1/k, size=( k, items))
    U = np.zeros((1,users))
    I = np.zeros((1,items))

    #Run gradient descent to minimize error
    stats = runGradientDescent(R,P,Q,U,I,iterations,alpha)
    
    print('P matrx:')
    print(P)
    print('Q matrix:')
    print(Q)
    print("User bias:")
    print(U)
    print("Item bias:")
    print(I)
    print("P x Q:")
    print(getPredictedRatings(P,Q,U,I))
    plotGraph(stats)
    return getPredictedRatings(P,Q,U,I)

def plotGraph(stats):
    i = [i for i,e in stats]
    e = [e for i,e in stats]
    print(e)
    plt.plot(i,e)
    plt.xlabel("Iterations")
    plt.ylabel("Mean Square Error")
    plt.show()    
    
""""
User Item rating matrix given ratings of 5 users for 6 items.
Note: If you want, you can change the underlying data structure and can work with starndard python lists instead of np arrays
We may test with different matrices with varying dimensions and number of latent factors. Make sure your code works fine in those cases.
"""
R = np.array([
[5, 3, 0, 1, 4, 5],
[1, 0, 2, 0, 0, 0],
[3, 1, 0, 5, 1, 3],
[2, 0, 0, 0, 2, 0],
[0, 1, 5, 2, 0, 0],
]) # == >
print(np.shape(R))

k = 3
alpha = 0.01
iterations = 500

matrixFactorization(R,k,iterations, alpha)

# ###############Optimizingg k over 1000 iterations
# error_stat = []
# for k in range(1, 50):
#     R = np.array([
#     [5, 3, 0, 1, 4, 5],
#     [1, 0, 2, 0, 0, 0],
#     [3, 1, 0, 5, 1, 3],
#     [2, 0, 0, 0, 2, 0],
#     [0, 1, 5, 2, 0, 0],
#     ]) # == >
#     print(np.shape(R))

#     k = 3
#     alpha = 0.01
#     iterations = 500

#     sas = k, computeError(R, matrixFactorization(R,k,iterations, alpha))
#     error_stat.append(sas)
